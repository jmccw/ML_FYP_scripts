{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec54dca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt \n",
    "from numpy.linalg import eig\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import clear_output\n",
    "import subprocess\n",
    "import random\n",
    "from datetime import datetime\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6751f63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = file.readlines()\n",
    "\n",
    "    # Extracting layers\n",
    "    layers = []\n",
    "    for line in data:\n",
    "        if line.strip() == 'Layers:':\n",
    "            break\n",
    "    for line in data[data.index('Layers:\\n') + 1:]:\n",
    "        if line.strip() == 'Materials:':\n",
    "            break\n",
    "        layer_info = line.strip().replace(\"(\", \"\").replace(\")\", \"\").replace(\"'\", \"\").split(', ')\n",
    "        layer = (layer_info[0], float(layer_info[1]))\n",
    "        layers.append(layer)\n",
    "\n",
    "    # Extracting materials\n",
    "    materials = {}\n",
    "    for line in data[data.index('Materials:\\n') + 1:]:\n",
    "        if line.strip() == 'QWI Target Shift:':\n",
    "            break\n",
    "        material_info = line.strip().split(': ')\n",
    "        material_name = material_info[0]\n",
    "        properties = [float(prop) for prop in material_info[1][1:-1].split(', ')]\n",
    "        materials[material_name] = properties\n",
    "\n",
    "    # Extracting QWI target shift\n",
    "    qwi_target_shift = float(data[data.index('QWI Target Shift:\\n') + 1])\n",
    "\n",
    "    # Extracting number of electric fields\n",
    "    number_of_electric_fields = int(data[data.index('Number of Electric Fields:\\n') + 1])\n",
    "\n",
    "    # Extracting max applied electric field\n",
    "    max_applied_electric_field = int(data[data.index('Max Applied Electric Field:\\n') + 1])\n",
    "\n",
    "    # Extracting FOM elements\n",
    "    fom_elements = [float(data[data.index('FOM:\\n') + i]) for i in range(1, 5)]\n",
    "\n",
    "    return materials, layers, qwi_target_shift, max_applied_electric_field, fom_elements\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# for files in file_path:\n",
    "#     file_path = 'data.txt'  # Replace 'your_file_path_here.txt' with the actual file path\n",
    "#     materials, layers, qwi_target_shift, max_applied_electric_field, fom_elements = read_data(file_path)\n",
    "#     input_ = [materials, layers, qwi_target_shift, max_applied_electric_field, fom_elements]\n",
    "#     print(input_)\n",
    "#     print(fom_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25c462e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "input_features_matrix=[]\n",
    "figure_of_merit=[]\n",
    "# Directory path\n",
    "directory = 'Z:\\FYP\\combined_data_sets'\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    # Check if the file is a text file\n",
    "    if filename.endswith('.txt'):\n",
    "        # Open the file\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        materials, layers, qwi_target_shift, max_applied_electric_field, fom_elements = read_data(file_path)\n",
    "        input_ = [materials, layers, qwi_target_shift, max_applied_electric_field, fom_elements]\n",
    "        input_features_matrix.append(input_)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc097345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'GaAs': [0.111, 1.42, 0.067, 0.08, 0.5, 3.9476],\n",
       "  'GaP': [-0.388, 2.74, 0.25, 0.14, 0.67, 3.3798],\n",
       "  'InP': [0.0, 1.35, 0.077, 0.12, 0.6, 3.3688],\n",
       "  'InAs': [0.441, 0.354, 0.023, 0.025, 0.4, 3.714],\n",
       "  'AlAs': [-0.4245, 2.95, 0.15, 0.16, 0.79, 2.994],\n",
       "  'In0.528378Ga0.254615Al0.217007As': [0.2232880459876067,\n",
       "   1.0273682873288552,\n",
       "   0.061762949,\n",
       "   0.06829977000000001,\n",
       "   0.51009423,\n",
       "   3.52027361518913],\n",
       "  'In0.5311183Ga0.417546Al0.0513357As': [0.29922348681464206,\n",
       "   0.8065615387768478,\n",
       "   0.0478916579,\n",
       "   0.054895349499999996,\n",
       "   0.46177552299999997,\n",
       "   3.539881800967616],\n",
       "  'In0.5319670000000012Ga0.468033Al-1.11468e-15As': [0.3187091531757405,\n",
       "   0.7499006886428017,\n",
       "   0.04359345199999986,\n",
       "   0.05074181499999985,\n",
       "   0.44680329999999957,\n",
       "   3.542847366859467],\n",
       "  'In0.5295380000000001Ga0.323578Al0.146884As': [0.2578501073178942,\n",
       "   0.9268679636001914,\n",
       "   0.0558917,\n",
       "   0.06262613,\n",
       "   0.48964256000000006,\n",
       "   3.529958110383502],\n",
       "  'In0.52948Ga0.320116Al0.150404As': [0.2561997140519237,\n",
       "   0.9316670135157787,\n",
       "   0.056186412,\n",
       "   0.06291092,\n",
       "   0.49066916000000005,\n",
       "   3.529495234846517],\n",
       "  'In0.5283169999999999Ga0.250977Al0.220706As': [0.221366796181396,\n",
       "   1.032954939862181,\n",
       "   0.06207265,\n",
       "   0.068599045,\n",
       "   0.51117304,\n",
       "   3.519775994633554],\n",
       "  'In0.53192328Ga0.465427Al0.00264972As': [0.31775055864118695,\n",
       "   0.7526881109590376,\n",
       "   0.04381530244,\n",
       "   0.050956197200000004,\n",
       "   0.4475760908,\n",
       "   3.542732366478428],\n",
       "  'In0.5310923Ga0.41599Al0.0529177As': [0.29859251387814206,\n",
       "   0.8083962957890607,\n",
       "   0.0480241079,\n",
       "   0.055023339500000004,\n",
       "   0.46223690300000003,\n",
       "   3.5397644301875415],\n",
       "  'In0.529461Ga0.318979Al0.15156As': [0.25565577492915,\n",
       "   0.9332486916861007,\n",
       "   0.05628319600000001,\n",
       "   0.06300444499999999,\n",
       "   0.4910063,\n",
       "   3.529342122774468],\n",
       "  'In0.529443Ga0.317901Al0.152656As': [0.25513918182147804,\n",
       "   0.9347508525109682,\n",
       "   0.05637495599999999,\n",
       "   0.06309311499999999,\n",
       "   0.49132593999999996,\n",
       "   3.529196472066977],\n",
       "  'In0.528298Ga0.249844Al0.221858As': [0.22076644575723414,\n",
       "   1.0347006520580573,\n",
       "   0.062169102000000004,\n",
       "   0.06869225000000001,\n",
       "   0.5115090200000001,\n",
       "   3.5196224132953606],\n",
       "  'In0.5319100500000001Ga0.464616Al0.00347395As': [0.3174514593659531,\n",
       "   0.7535578384240968,\n",
       "   0.04388429565,\n",
       "   0.05102286325,\n",
       "   0.4478164405,\n",
       "   3.5426958154161743],\n",
       "  'In0.5310845Ga0.415507Al0.0534085As': [0.29839648473939706,\n",
       "   0.8089663136394386,\n",
       "   0.048065187499999995,\n",
       "   0.055063032500000005,\n",
       "   0.46238001500000003,\n",
       "   3.5397277061800656],\n",
       "  'In0.5294369999999999Ga0.317547Al0.153016As': [0.2549692787753146,\n",
       "   0.9352449003334847,\n",
       "   0.0564051,\n",
       "   0.06312224500000001,\n",
       "   0.49143094,\n",
       "   3.5291485204067388]},\n",
       " [('In0.5294369999999999Ga0.317547Al0.153016As', 100.0),\n",
       "  ('In0.528298Ga0.249844Al0.221858As', 53.71391108083787),\n",
       "  ('In0.5319100500000001Ga0.464616Al0.00347395As', 40.559063853652525),\n",
       "  ('In0.5310845Ga0.415507Al0.0534085As', 46.21560011459216),\n",
       "  ('In0.5294369999999999Ga0.317547Al0.153016As', 100.0)],\n",
       " 3.8461538461538463,\n",
       " 10,\n",
       " [0.06786932477205676,\n",
       "  -0.014825969413696738,\n",
       "  2.3640360438399415,\n",
       "  -0.07975767699702407]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_features_matrix[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d47e8774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32175319210395825, 0.04814051282645505, 1.7640811507802625, 0.09042567680878609]\n",
      "Training data shapes:\n",
      "X_train shape: (3918, 37)\n",
      "y_train shape: (3918, 4)\n",
      "\n",
      "Testing data shapes:\n",
      "X_test shape: (980, 37)\n",
      "y_test shape: (980, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Initialize lists to store features and targets\n",
    "X_train_list = []\n",
    "y_train_list = []\n",
    "\n",
    "# Iterate over each heterostructure\n",
    "for heterostructure in input_features_matrix:\n",
    "    # Extract features and targets from the current heterostructure\n",
    "    materials = heterostructure[0]\n",
    "    layers = heterostructure[1]\n",
    "    qwi_target_shift = heterostructure[2]\n",
    "    max_applied_electric_field = heterostructure[3]\n",
    "    fom_elements = heterostructure[4]\n",
    "\n",
    "    # Initialize list to store material features in the correct order\n",
    "    material_features = []\n",
    "\n",
    "    # Iterate over each layer to ensure correct material ordering\n",
    "    for layer in layers:\n",
    "        material_key = layer[0]\n",
    "        if material_key in materials:\n",
    "            material_features.extend(materials[material_key])\n",
    "\n",
    "    # Flatten the layers list\n",
    "    layer_thicknesses = [thickness for _, thickness in layers]\n",
    "\n",
    "    # Combine all features into a single array\n",
    "    all_features = np.concatenate((material_features, layer_thicknesses, [qwi_target_shift], [max_applied_electric_field]))\n",
    "\n",
    "    # Append features to the features list\n",
    "    X_train_list.append(all_features)\n",
    "\n",
    "    # Append targets to the targets list\n",
    "    y_train_list.append(fom_elements)\n",
    "    \n",
    "print(fom_elements)\n",
    "\n",
    "# Print the shape of each element in X_train_list\n",
    "# for i, x in enumerate(X_train_list):\n",
    "#     print(f\"Element {i}: Shape = {x.shape}\")\n",
    "\n",
    "# Convert the lists to numpy arrays\n",
    "X_train = np.array(X_train_list)\n",
    "y_train = np.array(y_train_list)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training data shapes:\")\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"\\nTesting data shapes:\")\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b670ed1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shapes:\n",
      "X_train shape: (4775, 37)\n",
      "y_train shape: (4775, 4)\n",
      "\n",
      "Testing data shapes:\n",
      "X_test shape: (123, 37)\n",
      "y_test shape: (123, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Get the maximum shape among all elements in X_train_list\n",
    "max_shape = max(x.shape[0] for x in X_train_list)\n",
    "\n",
    "# Pad the elements to have the same shape\n",
    "X_train_padded = np.array([np.pad(x, (0, max_shape - x.shape[0]), mode='constant') for x in X_train_list])\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "y_train = np.array(y_train_list)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_padded, y_train, test_size=0.025, random_state=42)\n",
    "\n",
    "print(\"Training data shapes:\")\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"\\nTesting data shapes:\")\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3c97897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (fc1): Linear(in_features=37, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        #self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc3 = nn.Linear(256, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Build neural network model\n",
    "def build_model(input_size):\n",
    "    model = NeuralNetwork(input_size)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    return model, criterion, optimizer\n",
    "\n",
    "# Example usage:\n",
    "input_size = X_train.shape[1]  # Input size corresponds to the number of input features\n",
    "model, criterion, optimizer = build_model(input_size)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe3f26e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2000], Loss: 12.1151\n",
      "Epoch [11/2000], Loss: 8.6527\n",
      "Epoch [21/2000], Loss: 8.3563\n",
      "Epoch [31/2000], Loss: 8.1977\n",
      "Epoch [41/2000], Loss: 8.0779\n",
      "Epoch [51/2000], Loss: 7.9622\n",
      "Epoch [61/2000], Loss: 7.7552\n",
      "Epoch [71/2000], Loss: 7.4171\n",
      "Epoch [81/2000], Loss: 7.1147\n",
      "Epoch [91/2000], Loss: 7.5675\n",
      "Epoch [101/2000], Loss: 7.4870\n",
      "Epoch [111/2000], Loss: 7.4449\n",
      "Epoch [121/2000], Loss: 7.4378\n",
      "Epoch [131/2000], Loss: 7.3740\n",
      "Epoch [141/2000], Loss: 7.3210\n",
      "Epoch [151/2000], Loss: 7.2894\n",
      "Epoch [161/2000], Loss: 7.2502\n",
      "Epoch [171/2000], Loss: 7.1975\n",
      "Epoch [181/2000], Loss: 7.2014\n",
      "Epoch [191/2000], Loss: 7.1765\n",
      "Epoch [201/2000], Loss: 7.2114\n",
      "Epoch [211/2000], Loss: 7.1473\n",
      "Epoch [221/2000], Loss: 7.0974\n",
      "Epoch [231/2000], Loss: 7.0720\n",
      "Epoch [241/2000], Loss: 7.0315\n",
      "Epoch [251/2000], Loss: 6.9792\n",
      "Epoch [261/2000], Loss: 6.9726\n",
      "Epoch [271/2000], Loss: 6.9683\n",
      "Epoch [281/2000], Loss: 6.9466\n",
      "Epoch [291/2000], Loss: 7.0160\n",
      "Epoch [301/2000], Loss: 6.9296\n",
      "Epoch [311/2000], Loss: 6.9219\n",
      "Epoch [321/2000], Loss: 6.8824\n",
      "Epoch [331/2000], Loss: 6.8482\n",
      "Epoch [341/2000], Loss: 6.9345\n",
      "Epoch [351/2000], Loss: 6.8198\n",
      "Epoch [361/2000], Loss: 6.8795\n",
      "Epoch [371/2000], Loss: 6.7377\n",
      "Epoch [381/2000], Loss: 6.7788\n",
      "Epoch [391/2000], Loss: 6.9151\n",
      "Epoch [401/2000], Loss: 6.7479\n",
      "Epoch [411/2000], Loss: 6.7287\n",
      "Epoch [421/2000], Loss: 6.7271\n",
      "Epoch [431/2000], Loss: 6.7433\n",
      "Epoch [441/2000], Loss: 6.7443\n",
      "Epoch [451/2000], Loss: 6.7190\n",
      "Epoch [461/2000], Loss: 6.6688\n",
      "Epoch [471/2000], Loss: 6.7272\n",
      "Epoch [481/2000], Loss: 6.6750\n",
      "Epoch [491/2000], Loss: 6.6192\n",
      "Epoch [501/2000], Loss: 6.6132\n",
      "Epoch [511/2000], Loss: 6.6519\n",
      "Epoch [521/2000], Loss: 6.5848\n",
      "Epoch [531/2000], Loss: 6.6392\n",
      "Epoch [541/2000], Loss: 6.6052\n",
      "Epoch [551/2000], Loss: 6.6009\n",
      "Epoch [561/2000], Loss: 6.6020\n",
      "Epoch [571/2000], Loss: 6.5163\n",
      "Epoch [581/2000], Loss: 6.5684\n",
      "Epoch [591/2000], Loss: 6.5623\n",
      "Epoch [601/2000], Loss: 6.5153\n",
      "Epoch [611/2000], Loss: 6.5311\n",
      "Epoch [621/2000], Loss: 6.5691\n",
      "Epoch [631/2000], Loss: 6.5323\n",
      "Epoch [641/2000], Loss: 6.4871\n",
      "Epoch [651/2000], Loss: 6.4919\n",
      "Epoch [661/2000], Loss: 6.4818\n",
      "Epoch [671/2000], Loss: 6.4583\n",
      "Epoch [681/2000], Loss: 6.4574\n",
      "Epoch [691/2000], Loss: 6.4898\n",
      "Epoch [701/2000], Loss: 6.5285\n",
      "Epoch [711/2000], Loss: 6.4169\n",
      "Epoch [721/2000], Loss: 6.4356\n",
      "Epoch [731/2000], Loss: 6.4846\n",
      "Epoch [741/2000], Loss: 6.4862\n",
      "Epoch [751/2000], Loss: 6.4200\n",
      "Epoch [761/2000], Loss: 6.4218\n",
      "Epoch [771/2000], Loss: 6.3851\n",
      "Epoch [781/2000], Loss: 6.3591\n",
      "Epoch [791/2000], Loss: 6.4375\n",
      "Epoch [801/2000], Loss: 6.3573\n",
      "Epoch [811/2000], Loss: 6.3644\n",
      "Epoch [821/2000], Loss: 6.3864\n",
      "Epoch [831/2000], Loss: 6.4046\n",
      "Epoch [841/2000], Loss: 6.4468\n",
      "Epoch [851/2000], Loss: 6.3382\n",
      "Epoch [861/2000], Loss: 6.3466\n",
      "Epoch [871/2000], Loss: 6.3540\n",
      "Epoch [881/2000], Loss: 6.3764\n",
      "Epoch [891/2000], Loss: 6.3014\n",
      "Epoch [901/2000], Loss: 6.2961\n",
      "Epoch [911/2000], Loss: 6.5432\n",
      "Epoch [921/2000], Loss: 6.3041\n",
      "Epoch [931/2000], Loss: 6.4024\n",
      "Epoch [941/2000], Loss: 6.3928\n",
      "Epoch [951/2000], Loss: 6.4186\n",
      "Epoch [961/2000], Loss: 6.2916\n",
      "Epoch [971/2000], Loss: 6.3501\n",
      "Epoch [981/2000], Loss: 6.3429\n",
      "Epoch [991/2000], Loss: 6.3207\n",
      "Epoch [1001/2000], Loss: 6.2954\n",
      "Epoch [1011/2000], Loss: 6.4145\n",
      "Epoch [1021/2000], Loss: 6.3091\n",
      "Epoch [1031/2000], Loss: 6.4147\n",
      "Epoch [1041/2000], Loss: 6.2816\n",
      "Epoch [1051/2000], Loss: 6.2822\n",
      "Epoch [1061/2000], Loss: 6.3403\n",
      "Epoch [1071/2000], Loss: 6.2990\n",
      "Epoch [1081/2000], Loss: 6.2698\n",
      "Epoch [1091/2000], Loss: 6.2156\n",
      "Epoch [1101/2000], Loss: 6.2284\n",
      "Epoch [1111/2000], Loss: 6.2294\n",
      "Epoch [1121/2000], Loss: 6.3019\n",
      "Epoch [1131/2000], Loss: 6.2336\n",
      "Epoch [1141/2000], Loss: 6.2376\n",
      "Epoch [1151/2000], Loss: 6.2059\n",
      "Epoch [1161/2000], Loss: 6.1461\n",
      "Epoch [1171/2000], Loss: 6.1730\n",
      "Epoch [1181/2000], Loss: 6.2012\n",
      "Epoch [1191/2000], Loss: 6.1762\n",
      "Epoch [1201/2000], Loss: 6.1687\n",
      "Epoch [1211/2000], Loss: 6.1492\n",
      "Epoch [1221/2000], Loss: 6.1544\n",
      "Epoch [1231/2000], Loss: 6.1380\n",
      "Epoch [1241/2000], Loss: 6.1442\n",
      "Epoch [1251/2000], Loss: 6.1238\n",
      "Epoch [1261/2000], Loss: 6.1083\n",
      "Epoch [1271/2000], Loss: 6.1243\n",
      "Epoch [1281/2000], Loss: 6.1015\n",
      "Epoch [1291/2000], Loss: 6.1012\n",
      "Epoch [1301/2000], Loss: 6.1020\n",
      "Epoch [1311/2000], Loss: 6.0845\n",
      "Epoch [1321/2000], Loss: 6.0847\n",
      "Epoch [1331/2000], Loss: 6.0618\n",
      "Epoch [1341/2000], Loss: 6.0888\n",
      "Epoch [1351/2000], Loss: 6.0732\n",
      "Epoch [1361/2000], Loss: 6.1174\n",
      "Epoch [1371/2000], Loss: 6.0718\n",
      "Epoch [1381/2000], Loss: 6.0633\n",
      "Epoch [1391/2000], Loss: 6.0731\n",
      "Epoch [1401/2000], Loss: 6.0563\n",
      "Epoch [1411/2000], Loss: 6.0521\n",
      "Epoch [1421/2000], Loss: 6.0407\n",
      "Epoch [1431/2000], Loss: 6.0426\n",
      "Epoch [1441/2000], Loss: 6.0439\n",
      "Epoch [1451/2000], Loss: 6.0351\n",
      "Epoch [1461/2000], Loss: 6.0024\n",
      "Epoch [1471/2000], Loss: 6.0258\n",
      "Epoch [1481/2000], Loss: 5.9979\n",
      "Epoch [1491/2000], Loss: 6.0183\n",
      "Epoch [1501/2000], Loss: 6.0206\n",
      "Epoch [1511/2000], Loss: 6.0017\n",
      "Epoch [1521/2000], Loss: 5.9904\n",
      "Epoch [1531/2000], Loss: 5.9858\n",
      "Epoch [1541/2000], Loss: 6.0025\n",
      "Epoch [1551/2000], Loss: 6.0192\n",
      "Epoch [1561/2000], Loss: 5.9840\n",
      "Epoch [1571/2000], Loss: 5.9831\n",
      "Epoch [1581/2000], Loss: 5.9767\n",
      "Epoch [1591/2000], Loss: 5.9761\n",
      "Epoch [1601/2000], Loss: 5.9673\n",
      "Epoch [1611/2000], Loss: 5.9467\n",
      "Epoch [1621/2000], Loss: 5.9691\n",
      "Epoch [1631/2000], Loss: 5.9414\n",
      "Epoch [1641/2000], Loss: 5.9532\n",
      "Epoch [1651/2000], Loss: 5.9498\n",
      "Epoch [1661/2000], Loss: 5.9610\n",
      "Epoch [1671/2000], Loss: 5.9561\n",
      "Epoch [1681/2000], Loss: 5.9365\n",
      "Epoch [1691/2000], Loss: 5.9716\n",
      "Epoch [1701/2000], Loss: 5.9261\n",
      "Epoch [1711/2000], Loss: 5.9026\n",
      "Epoch [1721/2000], Loss: 5.9414\n",
      "Epoch [1731/2000], Loss: 5.9412\n",
      "Epoch [1741/2000], Loss: 5.9399\n",
      "Epoch [1751/2000], Loss: 5.9679\n",
      "Epoch [1761/2000], Loss: 5.9174\n",
      "Epoch [1771/2000], Loss: 5.9569\n",
      "Epoch [1781/2000], Loss: 5.9636\n",
      "Epoch [1791/2000], Loss: 5.9736\n",
      "Epoch [1801/2000], Loss: 5.9385\n",
      "Epoch [1811/2000], Loss: 5.9767\n",
      "Epoch [1821/2000], Loss: 5.9017\n",
      "Epoch [1831/2000], Loss: 5.9130\n",
      "Epoch [1841/2000], Loss: 5.9410\n",
      "Epoch [1851/2000], Loss: 5.9201\n",
      "Epoch [1861/2000], Loss: 5.8915\n",
      "Epoch [1871/2000], Loss: 5.8915\n",
      "Epoch [1881/2000], Loss: 5.8673\n",
      "Epoch [1891/2000], Loss: 5.8862\n",
      "Epoch [1901/2000], Loss: 5.8818\n",
      "Epoch [1911/2000], Loss: 5.8706\n",
      "Epoch [1921/2000], Loss: 5.8928\n",
      "Epoch [1931/2000], Loss: 5.8666\n",
      "Epoch [1941/2000], Loss: 5.8861\n",
      "Epoch [1951/2000], Loss: 5.8594\n",
      "Epoch [1961/2000], Loss: 5.8757\n",
      "Epoch [1971/2000], Loss: 5.8713\n",
      "Epoch [1981/2000], Loss: 5.9007\n",
      "Epoch [1991/2000], Loss: 5.9008\n",
      "Mean Squared Error (MSE) on test data: 0.1822\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Train the model\n",
    "def train_model(model, criterion, optimizer, X_train, y_train, epochs=2000):\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, targets in zip(X_train, y_train):\n",
    "            inputs = inputs.clone().detach().type(torch.float32)\n",
    "            targets = targets.clone().detach().type(torch.float32)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            targets = targets.view(-1)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(X_train)\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}')\n",
    "\n",
    "# Evaluate the model\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs = X_test.clone().detach().type(torch.float32)\n",
    "        targets = y_test.clone().detach().type(torch.float32)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        mse = mean_squared_error(targets.numpy(), outputs.numpy())\n",
    "        print(f'Mean Squared Error (MSE) on test data: {mse:.4f}')\n",
    "\n",
    "# Train and evaluate the model\n",
    "def train_and_evaluate_model(model, criterion, optimizer, X_train, y_train, X_test, y_test):\n",
    "    train_model(model, criterion, optimizer, X_train, y_train)\n",
    "    evaluate_model(model, X_test, y_test)\n",
    "\n",
    "# Convert input features and target values to numpy arrays\n",
    "X_train_np = np.array(X_train)\n",
    "y_train_np = np.array(y_train)\n",
    "X_test_np = np.array(X_test)\n",
    "y_test_np = np.array(y_test)\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_np, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_np, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_np, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_np, dtype=torch.float32)\n",
    "\n",
    "# Example usage:\n",
    "epochs = 2000\n",
    "batch_size = 256\n",
    "# Train and evaluate the model\n",
    "train_and_evaluate_model(model, criterion, optimizer, X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8591c936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f61f9334",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "# from your_module import NeuralNetwork  # Import your neural network class from the module where it's defined\n",
    "\n",
    "# Save the entire model with timestamp\n",
    "current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "model_path = f'trained_model_{current_time}.pth'\n",
    "torch.save(model, model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4443aac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = r'C:\\Users\\jmcc0\\Desktop\\FYP\\QWI\\trained_model_2024-04-08_00-28-10.pth'\n",
    "model = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f319198b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.4834e-01, 1.2453e+00, 7.2861e-02, 7.9024e-02, 5.4875e-01, 3.5187e+00,\n",
      "        3.1183e-01, 7.6989e-01, 4.5159e-02, 5.2255e-02, 4.5226e-01, 3.5420e+00,\n",
      "        3.1516e-01, 7.6022e-01, 4.4409e-02, 5.1530e-02, 4.4964e-01, 3.5424e+00,\n",
      "        1.3747e-01, 1.2769e+00, 7.4332e-02, 8.0445e-02, 5.5388e-01, 3.5246e+00,\n",
      "        1.4834e-01, 1.2453e+00, 7.2861e-02, 7.9024e-02, 5.4875e-01, 3.5187e+00,\n",
      "        1.0000e+02, 3.8176e+01, 4.6050e+01, 5.8135e+01, 1.0000e+02, 3.1250e+01,\n",
      "        1.0000e+01])\n",
      "Predicted values: [1.2232358  0.17685056 1.3957118  0.1140147 ]\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have a trained model named 'model'\n",
    "file_path = f\"Z:\\FYP\\data_2024-04-07_17-52-46.txt\"\n",
    "\n",
    "# Read the data from the file\n",
    "materials, layers, qwi_target_shift, max_applied_electric_field, fom_elements = read_data(file_path)\n",
    "\n",
    "# Extract material names from the 'Layers' data in order of appearance\n",
    "material_names_ordered = [layer[0] for layer in layers]\n",
    "\n",
    "# Flatten the materials dictionary in the order of appearance\n",
    "material_features = []\n",
    "for material_key in material_names_ordered:\n",
    "    if material_key in materials:\n",
    "        material_features.extend(materials[material_key])\n",
    "\n",
    "# Flatten the layers list\n",
    "layer_thicknesses = [thickness for _, thickness in layers]\n",
    "\n",
    "# Combine all features into a single array\n",
    "all_features = np.concatenate((material_features, layer_thicknesses, [qwi_target_shift], [max_applied_electric_field]))\n",
    "\n",
    "input_tensor = torch.tensor(all_features, dtype=torch.float32)\n",
    "print(input_tensor)\n",
    "# Pass input data through the model\n",
    "with torch.no_grad():\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    output_tensor = model(input_tensor)\n",
    "\n",
    "# Get the predicted values\n",
    "predicted_values = output_tensor.numpy()\n",
    "\n",
    "print(\"Predicted values:\", predicted_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "517e9437",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "x = 0.253914\n",
      "y = 0.217719\n",
      "x=0.253914 y=0.217719\n",
      "BG:1.0284407073758248\n",
      "x = 0.308618\n",
      "y = 0.162095\n",
      "x=0.308618 y=0.162095\n",
      "BG:0.9477931015928155\n",
      "x = 0.379309\n",
      "y = 0.0902157\n",
      "x=0.379309 y=0.0902157\n",
      "BG:0.8531917373254098\n",
      "x = 0.453459\n",
      "y = 0.0148187\n",
      "x=0.453459 y=0.0148187\n",
      "BG:0.7656815127529981\n",
      "x = 0.158675\n",
      "y = 0.31456\n",
      "x=0.158675 y=0.31456\n",
      "BG:1.1842281826514602\n",
      "x = 0.250693\n",
      "y = 0.220995\n",
      "x=0.250693 y=0.220995\n",
      "BG:1.033392844767674\n",
      "x = 0.305655\n",
      "y = 0.165109\n",
      "x=0.305655 y=0.165109\n",
      "BG:0.9519982016507235\n",
      "x = 0.376669\n",
      "y = 0.0929006\n",
      "x=0.376669 y=0.0929006\n",
      "BG:0.8565302629403297\n",
      "x = 0.451452\n",
      "y = 0.0168596\n",
      "x=0.451452 y=0.0168596\n",
      "BG:0.7678917118824079\n",
      "x = 0.157657\n",
      "y = 0.315595\n",
      "x=0.157657 y=0.315595\n",
      "BG:1.1859980945553752\n",
      "1501.5142286636644\n",
      "x = 0.249845\n",
      "y = 0.221857\n",
      "x=0.249845 y=0.221857\n",
      "BG:1.0346991511190275\n",
      "x = 0.304875\n",
      "y = 0.165902\n",
      "x=0.304875 y=0.165902\n",
      "BG:0.9531073369307344\n",
      "x = 0.375974\n",
      "y = 0.0936065\n",
      "x=0.375974 y=0.0936065\n",
      "BG:0.8574096110408733\n",
      "x = 0.450924\n",
      "y = 0.017396\n",
      "x=0.450924 y=0.017396\n",
      "BG:0.7684735484233625\n",
      "x = 0.157389\n",
      "y = 0.315868\n",
      "x=0.157389 y=0.315868\n",
      "BG:1.1864657500152789\n",
      "1500.3968791744915\n",
      "out: 1500.3968791744915\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model_evaluation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_48876\\2357261826.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;31m# Perform Bayesian optimization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgp_minimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective_with_constraint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearch_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_calls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;31m# Extract the optimized parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[1;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size, space_constraint)\u001b[0m\n\u001b[0;32m    279\u001b[0m         )\n\u001b[0;32m    280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 281\u001b[1;33m     return base_minimize(\n\u001b[0m\u001b[0;32m    282\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[0mspace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[1;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size, space_constraint)\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_calls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mnext_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m         \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_48876\\2357261826.py\u001b[0m in \u001b[0;36mobjective_with_constraint\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mobjective_with_constraint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mconstraint_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobjective_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;36m1e6\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_48876\\2357261826.py\u001b[0m in \u001b[0;36mobjective_function\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m# Evaluate your model and compute scores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_evaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Replace with your model evaluation function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Return the sum of scores as the objective\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_evaluation' is not defined"
     ]
    }
   ],
   "source": [
    "from skopt import gp_minimize\n",
    "from skopt.space import Real\n",
    "import numpy as np\n",
    "\n",
    "num_layers=5\n",
    "def objective_function(params):\n",
    "    layer_thicknesses = params[:num_layers]\n",
    "    bandgaps = params[num_layers:]\n",
    "\n",
    "    layers = [Layer(InGaAlAs_material(bandgap), thickness) for bandgap, thickness in zip(bandgaps, layer_thicknesses)]\n",
    "    if check:\n",
    "        scores = model_evaluation(layers)  # Replace with your model evaluation function\n",
    "        return sum(scores)  # Return the sum of scores as the objective\n",
    "    else:\n",
    "        return 1e6\n",
    "\n",
    "def constraint_check(params):\n",
    "    layer_thicknesses = params[:num_layers]\n",
    "    bandgaps = params[num_layers:]\n",
    "\n",
    "    layers = [Layer(InGaAlAs_material(bandgap), thickness) for bandgap, thickness in zip(bandgaps, layer_thicknesses)]\n",
    "    layers[0].thickness = 100\n",
    "    layers[-1].thickness = 100\n",
    "    \n",
    "    if (getGap(layers) > 1499 and getGap(layers) < 1551): \n",
    "        check = True\n",
    "    else: \n",
    "        check = False\n",
    "    clear_output()\n",
    "    print(check)\n",
    "    return check\n",
    "\n",
    "def objective_with_constraint(params):\n",
    "    if constraint_check(params):\n",
    "        return objective_function(params)\n",
    "    else:\n",
    "        return 1e6\n",
    "\n",
    "# Define the search space\n",
    "search_space = []\n",
    "for _ in range(num_layers):\n",
    "    search_space.append(Real(30, 100))  # Adjust the range as needed\n",
    "for _ in range(num_layers):\n",
    "    search_space.append(Real(900, 1650))  # Adjust the range as needed\n",
    "\n",
    "# Perform Bayesian optimization\n",
    "result = gp_minimize(objective_with_constraint, search_space, n_calls=50)\n",
    "\n",
    "# Extract the optimized parameters\n",
    "best_params = result.x\n",
    "best_score = result.fun\n",
    "\n",
    "# Output the results\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e175dea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt \n",
    "from numpy.linalg import eig\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import clear_output\n",
    "import subprocess\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "def getXY(BG_in):\n",
    "    # Define the command to run the compiled C++ executable\n",
    "    executable_path = r'C:\\Users\\jmcc0\\Desktop\\FYP\\Frank code\\getXY.exe'\n",
    "    run_command = [executable_path]\n",
    "\n",
    "    # Run the compiled C++ code\n",
    "    process = subprocess.Popen(run_command, stdin=subprocess.PIPE, stdout=subprocess.PIPE, cwd=r'C:\\Users\\jmcc0\\Desktop\\FYP\\Frank code')\n",
    "\n",
    "    # Provide input to the C++ program\n",
    "    BG = BG_in\n",
    "    process.stdin.write(str(BG).encode())\n",
    "    process.stdin.close()\n",
    "\n",
    "    # Read the output from the C++ program\n",
    "    output = process.stdout.read().decode().strip()\n",
    "    x_str, y_str = output.split('\\t')\n",
    "    x = float(x_str.split('=')[1])\n",
    "    y = float(y_str.split('=')[1])\n",
    "    # Now you have the x and y values from the C++ code\n",
    "    print(\"x =\", x)\n",
    "    print(\"y =\", y)\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "def getGap(layers):\n",
    "    with open('input.txt', 'w') as f:\n",
    "        f.write(str(int(len(layers))) + \"\\n\")\n",
    "        for layer in layers:\n",
    "            f.write(str(layer.material.name) + \" \" + str(layer.thickness) + \"\\n\")\n",
    "    with open('materials.txt', 'w') as f:\n",
    "        for material in materials:\n",
    "            f.write(material.name + \" \" + str(material.affinity) + \" \" + str(material.band_gap) + \" \" + str(material.e_eff_mass) + \" \" + str(material.lh_eff_mass) + \" \" + str(material.hh_eff_mass) + \" \" + str(material.refractive) + \"\\n\")\n",
    "        for material in alloys:\n",
    "            f.write(material.name + \" \" + str(material.affinity) + \" \" + str(material.band_gap) + \" \" + str(material.e_eff_mass) + \" \" + str(material.lh_eff_mass) + \" \" + str(material.hh_eff_mass) + \" \" + str(material.refractive) + \"\\n\")\n",
    "    \n",
    "    executable_path = r'C:\\Users\\jmcc0\\Desktop\\FYP\\QWI\\getGap.exe'\n",
    "    run_command = [executable_path]\n",
    "    process = subprocess.Popen(run_command, stdin=subprocess.PIPE, stdout=subprocess.PIPE, cwd=r'C:\\Users\\jmcc0\\Desktop\\FYP\\QWI')\n",
    "    \n",
    "    output = process.stdout.read().decode().strip()\n",
    "    lines = output.split('\\n')\n",
    "\n",
    "    # Initialize variables to store the values\n",
    "    energy_e = None\n",
    "    energy_lh = None\n",
    "    energy_hh = None\n",
    "\n",
    "    # Process each line\n",
    "    for line in lines:\n",
    "        parts = line.split(':')\n",
    "        if len(parts) == 2:  # Ensure the line has a label and a value\n",
    "            label = int(parts[0])\n",
    "            value = float(parts[1])\n",
    "            if label == 0:\n",
    "                energy_e = value\n",
    "            elif label == 1:\n",
    "                energy_lh = value\n",
    "            elif label == 2:\n",
    "                energy_hh = value\n",
    "                \n",
    "    print(max(1240/abs(energy_e-energy_lh), 1240/abs(energy_e-energy_hh)))\n",
    "    return max(1240/abs(energy_e-energy_lh), 1240/abs(energy_e-energy_hh))\n",
    "\n",
    "# voigt function details\n",
    "num_discrete = 2048\n",
    "func_x = np.zeros(num_discrete)\n",
    "Gauss_y = np.zeros(num_discrete)\n",
    "Lorentz_y = np.zeros(num_discrete)\n",
    "x_0 = num_discrete/2\n",
    "gamma = 50\n",
    "sigma = gamma\n",
    "PLOT_LIMIT=[]\n",
    "\n",
    "def pad_func_zeros(func):\n",
    "    func_new = np.zeros(2*len(func))\n",
    "    j = 0\n",
    "    for i in range(int(0.25*len(func_new)), int(0.75*len(func_new))):\n",
    "        func_new[i] = func[j]\n",
    "        j+=1\n",
    "    return func_new # twice in length\n",
    "\n",
    "def pad_func_linear(func):\n",
    "    func_new = np.zeros(2*len(func))\n",
    "    j = 0\n",
    "    del_f = np.abs(func[1]-func[2])\n",
    "    for i in range(0, int(0.25*len(func_new))):\n",
    "        func_new[i] = func[0]-0.5*(func[len(func)-1]-func[0]) + i*del_f\n",
    "    for i in range(int(0.25*len(func_new)), int(0.75*len(func_new))):\n",
    "        func_new[i] = func[j]\n",
    "        j+=1\n",
    "    w=j-1\n",
    "    j=1\n",
    "    for i in range(int(0.75*len(func_new)), len(func_new)):\n",
    "        func_new[i] = func[w] + j*del_f\n",
    "        j+=1\n",
    "    return func_new # twice in length\n",
    "\n",
    "def pad_E(f):\n",
    "    del_f = np.max(f)/(num_discrete-1)\n",
    "    func_new = np.zeros(2*len(f))\n",
    "    j = 0\n",
    "    for i in range(len(func_new)):\n",
    "        func_new[i] = del_f*i\n",
    "    return func_new # twice in length\n",
    "\n",
    "def convolve(f, g): # PAD ARRAYS BEFORE USE FRO ABSORPTION\n",
    "    FFT_f = np.fft.fft(f)\n",
    "    FFT_g = np.fft.fft(g)\n",
    "    FG = FFT_f * FFT_g\n",
    "    result = np.fft.ifft(FG)\n",
    "    return np.real(result)\n",
    "\n",
    "# plotting\n",
    "PLOT_LIMIT = []#400,800]\n",
    "Y_LIMIT = [] # leave blank for auto\n",
    "ERROR_BARS = False\n",
    "PLOT_FITTED = False\n",
    "split_ = \",\"\n",
    "LABEL_FONT_SIZE = 13\n",
    "TICK_FONT_SIZE = 11\n",
    "LINE_WIDTH = 0.5\n",
    "MARKER_SIZE = 1\n",
    "LEGEND = True\n",
    "label_x = \"\"\n",
    "label_y = \"\"\n",
    "plot_title = \"\"\n",
    "aspect_ratio = [9,9]\n",
    "\n",
    "colours = [ 'black', 'dimgrey', 'lightslategrey', 'lightsteelblue', 'silver', 'cadetblue', 'darkcyan', 'darkslategray', 'seagreen', 'mediumseagreen', 'darkolivegreen', 'olivedrab', 'olive', 'yellowgreen', 'green', 'springgreen', 'mediumspringgreen', 'turquoise', 'lightseagreen']\n",
    "\n",
    "def plot_graph(x, y): #create a single plot\n",
    "    labels = []\n",
    "    plt.figure()\n",
    "    plt.rcParams[\"figure.figsize\"] = (aspect_ratio[0],aspect_ratio[1])\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.title(plot_title)\n",
    "    plt.xlabel(label_x, fontsize=LABEL_FONT_SIZE)\n",
    "    plt.ylabel(label_y,  fontsize=LABEL_FONT_SIZE)\n",
    "    plt.xticks(fontsize = TICK_FONT_SIZE)\n",
    "    plt.yticks(fontsize = TICK_FONT_SIZE)\n",
    "    if(bool(Y_LIMIT) == True):\n",
    "        plt.ylim(Y_LIMIT)\n",
    "    if(bool(PLOT_LIMIT) == True):\n",
    "        plt.xlim(PLOT_LIMIT)\n",
    "    \n",
    "    right_side = ax.spines[\"right\"]\n",
    "    top_side = ax.spines[\"top\"]\n",
    "    right_side.set_visible(False)\n",
    "    top_side.set_visible(False)\n",
    "    plt.plot(x, y, linewidth = LINE_WIDTH, color = 'dimgrey', marker = 's', markersize = MARKER_SIZE, markerfacecolor='dimgrey')\n",
    "    plt.grid(True, alpha=0.2)\n",
    "    #labels = np.array(labels)\n",
    "    #plt.savefig(f'{file}_figure.png', dpi = 1000, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_graphs(x, y): #create a single plot\n",
    "    labels = []\n",
    "    plt.figure()\n",
    "    plt.rcParams[\"figure.figsize\"] = (6,6)\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.title(plot_title)\n",
    "    plt.xlabel(label_x, fontsize=LABEL_FONT_SIZE)\n",
    "    plt.ylabel(label_y,  fontsize=LABEL_FONT_SIZE)\n",
    "    #ax.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "    #plt.xticks(fontsize = TICK_FONT_SIZE)\n",
    "    #plt.yticks(fontsize = TICK_FONT_SIZE)\n",
    "    if(bool(Y_LIMIT) == True):\n",
    "        plt.ylim(Y_LIMIT)\n",
    "    if(bool(PLOT_LIMIT) == True):\n",
    "        plt.xlim(PLOT_LIMIT)\n",
    "    \n",
    "    right_side = ax.spines[\"right\"]\n",
    "    top_side = ax.spines[\"top\"]\n",
    "    right_side.set_visible(False)\n",
    "    top_side.set_visible(False)\n",
    "    i=0\n",
    "    for ys in y:\n",
    "        if i < len(colours):\n",
    "            plt.plot(x, ys, linewidth = LINE_WIDTH, marker = 's', markersize = MARKER_SIZE, color = colours[i])\n",
    "        else:\n",
    "            plt.plot(x, ys, linewidth = LINE_WIDTH, marker = 's', markersize = MARKER_SIZE)\n",
    "        i+=1\n",
    "    plt.grid(True, alpha=0.2)\n",
    "    if(LEGEND==True):\n",
    "        plt.legend(legend)\n",
    "    #labels = np.array(labels)\n",
    "    #plt.savefig(f'{file}_figure.png', dpi = 1000, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_graphs_distinct(x, y): #create a single plot\n",
    "    labels = []\n",
    "    plt.figure()\n",
    "    plt.rcParams[\"figure.figsize\"] = (6,6)\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.title(plot_title)\n",
    "    plt.xlabel(label_x, fontsize=LABEL_FONT_SIZE)\n",
    "    plt.ylabel(label_y,  fontsize=LABEL_FONT_SIZE)\n",
    "    #ax.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "    #plt.xticks(fontsize = TICK_FONT_SIZE)\n",
    "    #plt.yticks(fontsize = TICK_FONT_SIZE)\n",
    "    if(bool(Y_LIMIT) == True):\n",
    "        plt.ylim(Y_LIMIT)\n",
    "    if(bool(PLOT_LIMIT) == True):\n",
    "        plt.xlim(PLOT_LIMIT)\n",
    "    \n",
    "    right_side = ax.spines[\"right\"]\n",
    "    top_side = ax.spines[\"top\"]\n",
    "    right_side.set_visible(False)\n",
    "    top_side.set_visible(False)\n",
    "    i=0\n",
    "    for ys in y:\n",
    "        if i < len(colours):\n",
    "            plt.plot(x[i], ys, linewidth = LINE_WIDTH, marker = 's', markersize = MARKER_SIZE, color = colours[i])\n",
    "        else:\n",
    "            plt.plot(x[i], ys, linewidth = LINE_WIDTH, marker = 's', markersize = MARKER_SIZE)\n",
    "        i+=1\n",
    "    plt.grid(True, alpha=0.2)\n",
    "    if(LEGEND==True):\n",
    "        plt.legend(legend)\n",
    "    #labels = np.array(labels)\n",
    "    #plt.savefig(f'{file}_figure.png', dpi = 1000, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def make_array(y, number_steps):\n",
    "    p = np.zeros(number_steps)\n",
    "    for nr in range(0, number_steps):\n",
    "        p[nr] = y\n",
    "    return p\n",
    "\n",
    "def read_in(file_path):\n",
    "    x_data_ = []\n",
    "    y_data_ = []\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                # Split the line into x and y values\n",
    "                x_val, y_val = map(float, line.strip().split())\n",
    "                x_data_.append(x_val)\n",
    "                y_data_.append(y_val)\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found:\", file_path)\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    x_array_ = np.array(x_data_)\n",
    "    y_array_ = np.array(y_data_)\n",
    "    \n",
    "    #plot_graph(x_array_, y_array_)\n",
    "    \n",
    "    return x_array_, y_array_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a2915fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_simulation_parameters(inter_mixing_params, num_electric_fields, max_electric_field):\n",
    "    with open('simulation_parameters.txt', 'w') as f:\n",
    "        f.write(f\"{inter_mixing_params[0]} {inter_mixing_params[1]}\\n\")\n",
    "        f.write(f\"{num_electric_fields}\\n\")\n",
    "        f.write(f\"{max_electric_field}\\n\")\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self, material, thickness): # thickness in [A]\n",
    "        self.material = material\n",
    "        self.thickness = thickness\n",
    "\n",
    "class Material:\n",
    "    def __init__(self, name, affinity, band_gap, e_eff_mass, lh_eff_mass, hh_eff_mass, refractive):\n",
    "        self.affinity = affinity\n",
    "        self.band_gap = band_gap\n",
    "        self.e_eff_mass = e_eff_mass\n",
    "        self.lh_eff_mass = lh_eff_mass\n",
    "        self.hh_eff_mass = hh_eff_mass\n",
    "        self.name = name\n",
    "        self.refractive = refractive\n",
    "        \n",
    "    def getEffectiveMass(self, p):\n",
    "        if p == 0:\n",
    "            return self.e_eff_mass\n",
    "        if p == 1:\n",
    "            return self.lh_eff_mass\n",
    "        if p == 2:\n",
    "            return self.hh_eff_mass\n",
    "        \n",
    "    def getBandgap(self):\n",
    "        return self.band_gap\n",
    "    \n",
    "    def getRefractive(self):\n",
    "        return self.refractive\n",
    "    \n",
    "# Example Materials // BG = Bandgap, EF = Effective Electron Affinity for placing bands [REF: Takuya IEEE Quantum Electronics Vol 30, NO.2]\n",
    "# Decleration: Material(EF, BG, e_eff_mass, lh_eff_mass, hh_eff_mass, refractive index) \n",
    "GaAs = Material(\"GaAs\", 0.111, 1.42, 0.063, 0.082, 0.51, 3.9476)\n",
    "GaP = Material(\"GaP\", -0.388, 2.74, 0.25, 0.14, 0.67, 3.3798)\n",
    "InP = Material(\"InP\", 0.0, 1.35, 0.077, 0.14, 0.6, 3.3688)\n",
    "InAs = Material(\"InAs\", 0.441, 0.354, 0.023, 0.026, 0.41, 3.714)\n",
    "AlAs = Material(\"AlAs\", -0.4245, 2.95, 0.15, 0.16, 0.79, 2.9940) \n",
    "materials = [GaAs, GaP, InP, InAs, AlAs]\n",
    "# Simulation setup :: InGaAlAs\n",
    "alloys = []\n",
    "def BG_InGaAlAs(x, y):\n",
    "    return 0.36 + 2.093*y + 0.629*x + 0.577*y*y + 0.436*x*x + 1.013*x*y - 2.0*x*y*(1-x-y); # [eV]\n",
    "def EF_InGaAlAs(x, y): # Effective electron finity for placing conduction bands InGaAlAs\n",
    "    return 0.5766 - 0.3439*BG_InGaAlAs(x, y) # [eV] \n",
    "def effMass_InGaAlAs(x, y, particle):\n",
    "    return InAs.getEffectiveMass(particle)*(1-x-y) + GaAs.getEffectiveMass(particle)*(x) + AlAs.getEffectiveMass(particle)*(y);\n",
    "def refractive_InGaAlAs(x, y):\n",
    "    E_g = BG_InGaAlAs(x,y);\n",
    "    x=(E_g-0.75)/0.72;\n",
    "    w = 1240/E_g\n",
    "    if (x>1.0): x = 1\n",
    "    A = 9.689 - 1.012*x;\n",
    "    B = 1.590 - 0.376*x;\n",
    "    C = 1102.4 - 702.0*x + 330.4*x*x;\n",
    "    if (C+100 < w):\n",
    "        X = w*w-C*C\n",
    "    else: \n",
    "        X = (200*w+10000)\n",
    "    return np.sqrt(A + B*w*w/X);\n",
    "def InGaAlAs_material(bandgap): # in nm\n",
    "    bandgap = 1240/bandgap\n",
    "    x, y = getXY(bandgap)\n",
    "    print(\"x=\"+str(x)+\" y=\"+str(y))\n",
    "    temp = Material(\"In{}Ga{}Al{}As\".format(1-x-y,x,y), EF_InGaAlAs(x, y), BG_InGaAlAs(x, y), effMass_InGaAlAs(x, y, 0), effMass_InGaAlAs(x, y, 1), effMass_InGaAlAs(x, y, 2), refractive_InGaAlAs(x,y))\n",
    "    print(\"BG:\" + str(BG_InGaAlAs(x, y)))\n",
    "    alloys.append(temp)\n",
    "    return temp\n",
    "\n",
    "def findAlloys(layers, target):\n",
    "    layers[0].thickness = 100\n",
    "    layers[-1].thickness = 100\n",
    "    sigma = 2500\n",
    "    sigma0 = 500\n",
    "    sigma_prev = sigma0\n",
    "    i = 0\n",
    "    while i < 20:\n",
    "        for layer in layers:\n",
    "            if layer.material.name != 'InP':  # Exclude InP layers from modification\n",
    "                old_bandgap = 1240/layer.material.band_gap\n",
    "                new_bandgap = old_bandgap + (target - getGap(layers))  # Adjust each layer's bandgap individually\n",
    "                layer.material = InGaAlAs_material(new_bandgap)\n",
    "        with open('input.txt', 'w') as f:\n",
    "            f.write(str(int(len(layers))) + \"\\n\")\n",
    "            for layer in layers:\n",
    "                f.write(str(layer.material.name) + \" \" + str(layer.thickness) + \"\\n\")\n",
    "\n",
    "        with open('materials.txt', 'w') as f:\n",
    "            for material in materials:\n",
    "                f.write(material.name + \" \" + str(material.affinity) + \" \" + str(material.band_gap) + \" \" + str(material.e_eff_mass) + \" \" + str(material.lh_eff_mass) + \" \" + str(material.hh_eff_mass) + \" \" + str(material.refractive) + \"\\n\")\n",
    "            for material in alloys:\n",
    "                f.write(material.name + \" \" + str(material.affinity) + \" \" + str(material.band_gap) + \" \" + str(material.e_eff_mass) + \" \" + str(material.lh_eff_mass) + \" \" + str(material.hh_eff_mass) + \" \" + str(material.refractive) + \"\\n\")\n",
    "\n",
    "        testGap = getGap(layers)\n",
    "        temp = sigma\n",
    "        print(testGap)\n",
    "        if testGap > target + 1:\n",
    "            sigma = (sigma0 + sigma) / 2.0\n",
    "            sigma_prev = temp\n",
    "        elif testGap < target - 1:\n",
    "            sigma0 = sigma\n",
    "            sigma = (sigma_prev + sigma) / 2.0\n",
    "        else:\n",
    "            break\n",
    "        i += 1\n",
    "    if(i>=20): success = False\n",
    "    else: success = True\n",
    "    print(\"out: \" + str(testGap))\n",
    "    return layers, success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2e3f432d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_input_file(input_file):\n",
    "    layers = []\n",
    "    with open(input_file, 'r') as f:\n",
    "        num_layers = int(f.readline().strip())\n",
    "        for _ in range(num_layers):\n",
    "            layer_info = f.readline().strip().split()\n",
    "            material = layer_info[0]\n",
    "            thickness = float(layer_info[1])\n",
    "            layers.append((material, thickness))\n",
    "    return layers\n",
    "\n",
    "def parse_materials_file(materials_file):\n",
    "    materials = {}\n",
    "    with open(materials_file, 'r') as f:\n",
    "        for line in f:\n",
    "            material_info = line.strip().split()\n",
    "            material = material_info[0]\n",
    "            properties = [float(prop) for prop in material_info[1:]]\n",
    "            materials[material] = properties\n",
    "    return materials\n",
    "\n",
    "def parse_simulation_parameters_file(simulation_params_file):\n",
    "    with open(simulation_params_file, 'r') as f:\n",
    "        qwi_target_shift = float(f.readline().split(\" \")[1])\n",
    "        num_electric_fields = int(f.readline().strip())\n",
    "        max_applied_efield = float(f.readline().strip())\n",
    "    return qwi_target_shift, num_electric_fields, max_applied_efield\n",
    "\n",
    "def write_data_to_file(filename, data_dict):\n",
    "    with open(filename, 'w') as f:\n",
    "        for key, value in data_dict.items():\n",
    "            f.write(f\"{key}:\\n\")\n",
    "            if isinstance(value, list):\n",
    "                for item in value:\n",
    "                    f.write(f\"{item}\\n\")\n",
    "            elif isinstance(value, dict):\n",
    "                for subkey, subvalue in value.items():\n",
    "                    f.write(f\"{subkey}: {subvalue}\\n\")\n",
    "            else:\n",
    "                f.write(f\"{value}\\n\")\n",
    "\n",
    "def read_data_from_file(filename):\n",
    "    data_dict = {}\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        i = 0\n",
    "        while i < len(lines):\n",
    "            key = lines[i].strip(\":\\n\")\n",
    "            i += 1\n",
    "            if key in [\"Layers\", \"Materials\"]:\n",
    "                data_dict[key] = {}\n",
    "                while i < len(lines) and lines[i] != \"\\n\":\n",
    "                    line = lines[i].strip(\"\\n\")\n",
    "                    if line and \":\" in line:\n",
    "                        subkey, subvalue = line.split(\": \", 1)  # Limit split to 1 occurrence\n",
    "                        data_dict[key][subkey] = subvalue\n",
    "                    i += 1\n",
    "            else:\n",
    "                if i < len(lines):\n",
    "                    value = lines[i].strip(\"\\n\")\n",
    "                    data_dict[key] = value\n",
    "                    i += 1\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f266d436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers: [('In0.5308573999999999Ga0.402031Al0.0671116As', 100.0), ('In0.528136Ga0.2402Al0.231664As', 88.9827589220059), ('In0.5270600000000001Ga0.176191Al0.296749As', 58.744346491572486), ('In0.529802Ga0.339226Al0.130972As', 62.907533859634434), ('In0.5308573999999999Ga0.402031Al0.0671116As', 100.0)]\n",
      "QWI Target Shift: 0.0\n",
      "Number of Electric Fields: 10\n",
      "Max Applied Electric Field: 10\n",
      "FOM: [0, 0, 0, 0]\n",
      "tensor([2.9285e-01, 8.2510e-01, 4.7604e-02, 5.7507e-02, 4.7571e-01, 3.5386e+00,\n",
      "        2.1562e-01, 1.0497e+00, 6.2029e-02, 7.0494e-02, 5.2205e-01, 3.5183e+00,\n",
      "        1.7970e-01, 1.1541e+00, 6.7735e-02, 7.5631e-02, 5.4038e-01, 3.5131e+00,\n",
      "        2.6520e-01, 9.0550e-01, 5.3202e-02, 6.2547e-02, 4.9369e-01, 3.5320e+00,\n",
      "        2.9285e-01, 8.2510e-01, 4.7604e-02, 5.7507e-02, 4.7571e-01, 3.5386e+00,\n",
      "        1.0000e+02, 8.8983e+01, 5.8744e+01, 6.2908e+01, 1.0000e+02, 0.0000e+00,\n",
      "        1.0000e+01])\n",
      "Predicted values: [ 0.32988483 -0.19017376  2.4211264   0.01276863]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.4211264"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_electric_field = 10\n",
    "def objective_function_model():\n",
    "    input_file = \"input.txt\"\n",
    "    materials_file = \"materials.txt\"\n",
    "    simulation_params_file = \"simulation_parameters.txt\"\n",
    "    layers = parse_input_file(input_file)\n",
    "    materials_out = parse_materials_file(materials_file)\n",
    "    FOM_data = [0, 0, 0, 0]\n",
    "    qwi_target_shift, num_electric_fields, efield = parse_simulation_parameters_file(simulation_params_file)\n",
    "    print(\"Layers:\", layers)\n",
    "    # print(\"Materials:\", materials_out)\n",
    "    print(\"QWI Target Shift:\", qwi_target_shift)\n",
    "    print(\"Number of Electric Fields:\", num_electric_fields)\n",
    "    print(\"Max Applied Electric Field:\", max_electric_field)\n",
    "    print(\"FOM:\", FOM_data)\n",
    "\n",
    "    data_dict = {\n",
    "        \"Layers\": layers,\n",
    "        \"Materials\": materials_out,\n",
    "        \"QWI Target Shift\": qwi_target_shift,\n",
    "        \"Number of Electric Fields\": num_electric_fields,\n",
    "        \"Max Applied Electric Field\": max_electric_field,\n",
    "        \"FOM\": FOM_data\n",
    "    }\n",
    "    write_data_to_file(\"optimised.txt\", data_dict)\n",
    "    file_path = r\"optimised.txt\"\n",
    "    # Read the data from the file\n",
    "    materials, layers, qwi_target_shift, max_applied_electric_field, fom_elements = read_data(file_path)\n",
    "\n",
    "    # Extract material names from the 'Layers' data in order of appearance\n",
    "    material_names_ordered = [layer[0] for layer in layers]\n",
    "\n",
    "    # Flatten the materials dictionary in the order of appearance\n",
    "    material_features = []\n",
    "    for material_key in material_names_ordered:\n",
    "        if material_key in materials:\n",
    "            material_features.extend(materials[material_key])\n",
    "\n",
    "    # Flatten the layers list\n",
    "    layer_thicknesses = [thickness for _, thickness in layers]\n",
    "\n",
    "    # Combine all features into a single array\n",
    "    all_features = np.concatenate((material_features, layer_thicknesses, [qwi_target_shift], [max_applied_electric_field]))\n",
    "\n",
    "    input_tensor = torch.tensor(all_features, dtype=torch.float32)\n",
    "    print(input_tensor)\n",
    "    # Pass input data through the model\n",
    "    with torch.no_grad():\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        output_tensor = model(input_tensor)\n",
    "\n",
    "    # Get the predicted values\n",
    "    predicted_values = output_tensor.numpy()\n",
    "\n",
    "    print(\"Predicted values:\", predicted_values)\n",
    "    return predicted_values[2]\n",
    "    \n",
    "objective_function_model()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b2c4a2ca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false\n",
      "200\n",
      "penalty: 8.887704236886293\n",
      "Optimized thicknesses: [27.0, 58.15505279291747, 60.0]\n",
      "Optimized bandgaps: [1184.3736555850817, 1523.37091950054, 1412.1710271335708, 1625.1830535398785]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "max_electric_field = 10\n",
    "def objective_function_model():\n",
    "    input_file = \"input.txt\"\n",
    "    materials_file = \"materials.txt\"\n",
    "    simulation_params_file = \"simulation_parameters.txt\"\n",
    "    layers = parse_input_file(input_file)\n",
    "    materials_out = parse_materials_file(materials_file)\n",
    "    FOM_data = [0, 0, 0, 0]\n",
    "    qwi_target_shift, num_electric_fields, efield = parse_simulation_parameters_file(simulation_params_file)\n",
    "    print(\"Layers:\", layers)\n",
    "    # print(\"Materials:\", materials_out)\n",
    "    print(\"QWI Target Shift:\", qwi_target_shift)\n",
    "    print(\"Number of Electric Fields:\", num_electric_fields)\n",
    "    print(\"Max Applied Electric Field:\", max_electric_field)\n",
    "    print(\"FOM:\", FOM_data)\n",
    "\n",
    "    data_dict = {\n",
    "        \"Layers\": layers,\n",
    "        \"Materials\": materials_out,\n",
    "        \"QWI Target Shift\": qwi_target_shift,\n",
    "        \"Number of Electric Fields\": num_electric_fields,\n",
    "        \"Max Applied Electric Field\": max_electric_field,\n",
    "        \"FOM\": FOM_data\n",
    "    }\n",
    "    write_data_to_file(\"optimised.txt\", data_dict)\n",
    "    file_path = r\"optimised.txt\"\n",
    "    # Read the data from the file\n",
    "    materials, layers, qwi_target_shift, max_applied_electric_field, fom_elements = read_data(file_path)\n",
    "\n",
    "    # Extract material names from the 'Layers' data in order of appearance\n",
    "    material_names_ordered = [layer[0] for layer in layers]\n",
    "\n",
    "    # Flatten the materials dictionary in the order of appearance\n",
    "    material_features = []\n",
    "    for material_key in material_names_ordered:\n",
    "        if material_key in materials:\n",
    "            material_features.extend(materials[material_key])\n",
    "\n",
    "    # Flatten the layers list\n",
    "    layer_thicknesses = [thickness for _, thickness in layers]\n",
    "\n",
    "    # Combine all features into a single array\n",
    "    all_features = np.concatenate((material_features, layer_thicknesses, [qwi_target_shift], [max_applied_electric_field]))\n",
    "\n",
    "    input_tensor = torch.tensor(all_features, dtype=torch.float32)\n",
    "    print(input_tensor)\n",
    "    # Pass input data through the model\n",
    "    with torch.no_grad():\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        output_tensor = model(input_tensor)\n",
    "\n",
    "    # Get the predicted values\n",
    "    predicted_values = output_tensor.numpy()\n",
    "\n",
    "    print(\"Predicted values:\", predicted_values)\n",
    "    return predicted_values[2]\n",
    "    \n",
    "objective_function_model()\n",
    "    \n",
    "\n",
    "# Define the search space for thicknesses and bandgaps\n",
    "space_thickness = [Real(27, 60, name=f'thickness_{i}') for i in range(3)]  # Thickness for layers 1, 2, 3\n",
    "space_bandgap = [Real(1000, 1650, name=f'bandgap_{i}') for i in range(4)]  # Bandgap for all layers\n",
    "\n",
    "count = 0\n",
    "successes = 0\n",
    "\n",
    "# Additional constraint: The first and last layers should have the same bandgap\n",
    "def objective_function(thicknesses, bandgaps):\n",
    "    # Set the thickness for the layers\n",
    "    thicknesses = [100] + thicknesses + [100]\n",
    "    global count\n",
    "    global successes\n",
    "    count+=1\n",
    "    # Set the bandgap for the layers\n",
    "    # Ensure the last bandgap is equal to the first\n",
    "    bandgaps_reordered = [bandgaps[0]] + bandgaps[1:] + [bandgaps[0]]\n",
    "    \n",
    "    # Check if the bandgap of the entire heterostructure is within the tolerance\n",
    "    bandgap_tolerance = 1.5\n",
    "    target_bandgap = 1500\n",
    "    \n",
    "    global alloys\n",
    "    alloys=[]\n",
    "    # Create the heterostructure\n",
    "    layers = [Layer(InGaAlAs_material(bandgaps_reordered[i]), thicknesses[i]) for i in range(5)]  # Use bandgaps from optimization space\n",
    "    gapp = getGap(layers)\n",
    "    # Check the bandgap of the entire heterostructure\n",
    "    if abs(gapp - target_bandgap) <= bandgap_tolerance:\n",
    "        # Evaluate the figure of merit using the model\n",
    "        fom = objective_function_model()\n",
    "        clear_output()\n",
    "        print(\"true\")\n",
    "        print(count)\n",
    "        print(\"FOM: \" + str(fom))\n",
    "        print(\"GAP: \" + str(getGap(layers)))\n",
    "        successes+=1\n",
    "        return -fom  # Return figure of merit for maximization\n",
    "    else:\n",
    "        clear_output()\n",
    "        print(\"false\")\n",
    "        print(count)\n",
    "        penalty = abs(gapp - target_bandgap)*2\n",
    "        print(\"penalty: \" + str(penalty))\n",
    "        # Return a large positive value for designs with bandgap not within the tolerance\n",
    "        return penalty  # penalty for designs not meeting the constraint\n",
    "\n",
    "# Define the objective function using the trained model\n",
    "@use_named_args(space_thickness + space_bandgap)\n",
    "def objective(**params):\n",
    "    thicknesses = [params[f'thickness_{i}'] for i in range(3)]  # Only consider thicknesses for layers 1, 2, 3\n",
    "    bandgaps = [params[f'bandgap_{i}'] for i in range(4)]  # Consider bandgaps for all layers\n",
    "    return objective_function(thicknesses, bandgaps)\n",
    "\n",
    "# InP_layer2 = Layer(InGaAlAs_material(1239.85), 100)\n",
    "# layer1 = Layer(InGaAlAs_material(1650.85), 49)\n",
    "# layer2 = Layer(InGaAlAs_material(1400.85), 60)\n",
    "# layer3 = Layer(InGaAlAs_material(1000.00), 40)\n",
    "# layer4 = Layer(InGaAlAs_material(1650.85), 30)\n",
    "\n",
    "# layers = [InP_layer2, layer4, layer2, layer1, InP_layer2]\n",
    "\n",
    "# Initial guess for thicknesses and bandgaps\n",
    "initial_thicknesses = [30, 30, 60]  # Example initial guess for thicknesses\n",
    "initial_bandgaps = [1194.766898954708, 1624.720691840501, 1369.6999642066814, 1617.95942947708]  # Example initial guess for bandgaps\n",
    "\n",
    "# Concatenate initial guesses\n",
    "initial_guess = initial_thicknesses + initial_bandgaps\n",
    "\n",
    "# Optimize the heterostructure composition starting from the initial guess\n",
    "result = gp_minimize(objective, space_thickness + space_bandgap, x0=initial_guess, n_calls=300)\n",
    "\n",
    "# Get the optimized thicknesses and bandgaps\n",
    "optimized_thicknesses = result.x[:3]  # First 3 elements correspond to thicknesses\n",
    "optimized_bandgaps = result.x[3:]    # Last 4 elements correspond to bandgaps\n",
    "\n",
    "print(\"Optimized thicknesses:\", optimized_thicknesses)\n",
    "print(\"Optimized bandgaps:\", optimized_bandgaps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de03e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f733c6bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1941ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f3df5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "86b1e056",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false\n",
      "286\n",
      "x = 0.214499\n",
      "y = 0.257797\n",
      "x=0.214499 y=0.257797\n",
      "BG:1.090551242535432\n",
      "x = 0.276844\n",
      "y = 0.194403\n",
      "x=0.276844 y=0.194403\n",
      "BG:0.9938475345347901\n",
      "x = 0.368528\n",
      "y = 0.101178\n",
      "x=0.368528 y=0.101178\n",
      "BG:0.8669164162977655\n",
      "x = 0.321674\n",
      "y = 0.14882\n",
      "x=0.321674 y=0.14882\n",
      "BG:0.9295043215735599\n",
      "x = 0.214499\n",
      "y = 0.257797\n",
      "x=0.214499 y=0.257797\n",
      "BG:1.090551242535432\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21512\\382546031.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselBest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m \u001b[0mbest_individual\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenetic_algorithm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[0moptimized_thicknesses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest_individual\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[0moptimized_bandgaps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest_individual\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21512\\382546031.py\u001b[0m in \u001b[0;36mgenetic_algorithm\u001b[1;34m()\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[0minvalid_individuals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moffspring\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mfitnesses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoolbox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minvalid_individuals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minvalid_individuals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfitnesses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m             \u001b[0mind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21512\\382546031.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(individual)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mthicknesses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindividual\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mbandgaps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindividual\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mobjective_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthicknesses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbandgaps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# Define the individual creation function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21512\\382546031.py\u001b[0m in \u001b[0;36mobjective_function\u001b[1;34m(thicknesses, bandgaps)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;31m# Check the bandgap of the entire heterostructure\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetGap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtarget_bandgap\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mbandgap_tolerance\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[1;31m# Evaluate the figure of merit using the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mfom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobjective_function_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21512\\4193916166.py\u001b[0m in \u001b[0;36mgetGap\u001b[1;34m(layers)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mprocess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstdin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mr'C:\\Users\\jmcc0\\Desktop\\FYP\\QWI'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m     \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real\n",
    "from skopt.utils import use_named_args\n",
    "from deap import base, creator, tools\n",
    "\n",
    "# Define the evaluation function (objective function)\n",
    "def evaluate(individual):\n",
    "    thicknesses = individual[:3]\n",
    "    bandgaps = individual[3:]\n",
    "    return objective_function(thicknesses, bandgaps),\n",
    "\n",
    "# Define the individual creation function\n",
    "def create_individual():\n",
    "    thicknesses = [random.uniform(30, 100) for _ in range(3)]\n",
    "    bandgaps = [random.uniform(1000, 1660) for _ in range(4)]\n",
    "    return thicknesses + bandgaps\n",
    "\n",
    "# Register necessary DEAP components\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"individual\", tools.initIterate, creator.Individual, create_individual)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"evaluate\", evaluate)\n",
    "toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)\n",
    "toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=1, indpb=0.1)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "# Define the objective function\n",
    "def objective_function(thicknesses, bandgaps):\n",
    "    # Set the thickness for the layers\n",
    "    thicknesses = [100] + thicknesses + [100]\n",
    "    global count\n",
    "    count+=1\n",
    "    # Set the bandgap for the layers\n",
    "    # Ensure the last bandgap is equal to the first\n",
    "    bandgaps_reordered = [bandgaps[0]] + bandgaps[1:] + [bandgaps[0]]\n",
    "    \n",
    "    # Check if the bandgap of the entire heterostructure is within the tolerance\n",
    "    bandgap_tolerance = 1.5\n",
    "    target_bandgap = 1500\n",
    "    \n",
    "    global alloys\n",
    "    alloys=[]\n",
    "    # Create the heterostructure\n",
    "    layers = [Layer(InGaAlAs_material(bandgaps_reordered[i]), thicknesses[i]) for i in range(5)]  # Use bandgaps from optimization space\n",
    "    \n",
    "    # Check the bandgap of the entire heterostructure\n",
    "    if abs(getGap(layers) - target_bandgap) <= bandgap_tolerance:\n",
    "        # Evaluate the figure of merit using the model\n",
    "        fom = objective_function_model()\n",
    "        clear_output()\n",
    "        print(\"true\")\n",
    "        print(count)\n",
    "        print(\"FOM: \" + str(fom))\n",
    "        print(\"GAP: \" + str(getGap(layers)))\n",
    "        return -fom  # Return figure of merit for maximization\n",
    "    else:\n",
    "        clear_output()\n",
    "        print(\"false\")\n",
    "        print(count)\n",
    "        # Return a large positive value for designs with bandgap not within the tolerance\n",
    "        return 1  # Large penalty for designs not meeting the constraint\n",
    "\n",
    "# Remaining parts of your code\n",
    "\n",
    "# Run the genetic algorithm\n",
    "def genetic_algorithm():\n",
    "    population_size = 50\n",
    "    num_generations = 50\n",
    "    population = toolbox.population(n=population_size)\n",
    "    \n",
    "    for gen in range(num_generations):\n",
    "        offspring = toolbox.select(population, len(population))\n",
    "        offspring = list(map(toolbox.clone, offspring))\n",
    "\n",
    "        for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "            if random.random() < 0.5:\n",
    "                toolbox.mate(child1, child2)\n",
    "                del child1.fitness.values\n",
    "                del child2.fitness.values\n",
    "        \n",
    "        for mutant in offspring:\n",
    "            if random.random() < 0.2:\n",
    "                toolbox.mutate(mutant)\n",
    "                del mutant.fitness.values\n",
    "        \n",
    "        invalid_individuals = [ind for ind in offspring if not ind.fitness.valid]\n",
    "        fitnesses = map(toolbox.evaluate, invalid_individuals)\n",
    "        for ind, fit in zip(invalid_individuals, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "        \n",
    "        population[:] = offspring\n",
    "    \n",
    "    return tools.selBest(population, k=1)[0]\n",
    "\n",
    "best_individual = genetic_algorithm()\n",
    "optimized_thicknesses = best_individual[:3]\n",
    "optimized_bandgaps = best_individual[3:]\n",
    "\n",
    "print(\"Optimized thicknesses:\", optimized_thicknesses)\n",
    "print(\"Optimized bandgaps:\", optimized_bandgaps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a2c438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cff4ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b766fbc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7baddb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58432ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
